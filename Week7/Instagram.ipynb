{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Crawling & Scraping (Instagram)\n",
    "\n",
    "This script scrapes Instagram posts using Selenium & BeautifulSoup packages.\n",
    "\n",
    "Ref (2019): https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058\n",
    "\n",
    "Ref (2021): https://medium.com/analytics-vidhya/web-scraping-instagram-with-selenium-python-b8e77af32ad4\n",
    "\n",
    "Ref (2021): http://www.easy2digital.com/automation/python-tutorial-for-digital-marketer-12-using-hashtags-to-scrape-top-instagram-posts-and-instagram-users/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will specify Instagram profile's username\n",
    "And scrape the profile's posts.\n",
    "\n",
    "On your computer, you need to:\n",
    "\n",
    "1. Install Python selenium package\n",
    "> conda install -c conda-forge selenium\n",
    "\n",
    "OR\n",
    "\n",
    "> pip install selenium\n",
    "\n",
    "Ref: https://medium.com/@praneeth.jm/running-chromedriver-and-selenium-in-python-on-an-aws-ec2-instance-2fb4ad633bb5\n",
    "\n",
    "2. Install chromedriver\n",
    "\n",
    "3. Install Google Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the web browser\n",
    "# Selenium uses Chrome Drive to open the profile given a username (public user).\n",
    "# For example -\n",
    "\n",
    "username='davidbeckham'\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://www.instagram.com/'+username+'/?hl=en')\n",
    "Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the new Chrome browser window (used by Selenium)\n",
    "# Log into Instagram (using your own account)\n",
    "# Otherwise, crawler will not be able to retrieve posts from multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to open a hashtag page\n",
    "# hashtag='food'\n",
    "# browser = webdriver.Chrome()\n",
    "# browser.get('https://www.instagram.com/explore/tags/'+hashtag)\n",
    "# Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse HTML source page\n",
    "\n",
    "Open the source page and use beautiful soup to parse it.\n",
    "\n",
    "Go through the body of HTML script and extract link for each image in that page\n",
    "and pass it to an empty list 'links[]'.\n",
    "'''\n",
    "\n",
    "links = []\n",
    "source = browser.page_source\n",
    "data = bs(source, 'html.parser')\n",
    "\n",
    "body = data.find('body')\n",
    "script = body.find_all(\"div\",class_=\"v1Nh3\")\n",
    "\n",
    "\n",
    "for div in script:\n",
    "     link = div.find('a')\n",
    "     if re.match(\"/p\", link.get('href')):\n",
    "        links.append('https://www.instagram.com' + link.get('href'))\n",
    "        \n",
    "print(\"Number of Instagram images: \", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remember by default selenium opens only first page.\n",
    "\n",
    "If you want to scroll through further pages and get more images,\n",
    "divide the scroll Height by a number and run the parse code multiple times.\n",
    "\n",
    "This adds new links from each page to the list. For example -\n",
    "'''\n",
    "\n",
    "\n",
    "Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight/1.5);\")\n",
    "source = browser.page_source\n",
    "data = bs(source, 'html.parser')\n",
    "body = data.find('body')\n",
    "script = body.find('span')\n",
    "for link in script.findAll('a'):\n",
    "     if re.match(\"/p\", link.get('href')):\n",
    "         links.append('https://www.instagram.com' + link.get('href'))\n",
    "\n",
    "\n",
    "# === IMPORTANT ===\n",
    "# sleep time is required.\n",
    "# If you don't use this, Instagram may interrupt the script and doesn't scroll through pages.\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "Pagelength = browser.execute_script(\"window.scrollTo(document.body.scrollHeight/1.5, document.body.scrollHeight/3.0);\")\n",
    "source = browser.page_source\n",
    "data = bs(source, 'html.parser')\n",
    "\n",
    "body = data.find('body')\n",
    "script = body.find_all(\"div\",class_=\"v1Nh3\")\n",
    "\n",
    "for div in script:\n",
    "     link = div.find('a')\n",
    "     if re.match(\"/p\", link.get('href')):\n",
    "        links.append('https://www.instagram.com' + link.get('href'))\n",
    "        \n",
    "print(\"Number of Instagram images: \", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get information for each image in the page\n",
    "\n",
    "To get more details of each image such as\n",
    "\n",
    "who posted it\n",
    "post type\n",
    "image url\n",
    "image catpion\n",
    "number of likes\n",
    "comments\n",
    "\n",
    "\n",
    "open the source page of each image (from 'links' list in previous code)\n",
    "and extract the JSON script to pandas dataframe.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "result = pd.DataFrame()\n",
    "#for i in range(len(links)):\n",
    "for link in links:\n",
    "    try:\n",
    "        page = urlopen(link).read()\n",
    "        data = bs(page, 'html.parser')\n",
    "        body = data.find('body')\n",
    "        script = body.find('script')\n",
    "        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        \n",
    "        json_data = json.loads(raw)\n",
    "        \n",
    "        posts = json_data['entry_data']['PostPage'][0]['graphql']\n",
    "        posts = json.dumps(posts)\n",
    "        posts = json.loads(posts)\n",
    "        \n",
    "        print(posts)\n",
    "        \n",
    "        x = pd.DataFrame.from_dict(json_normalize(posts), orient='columns') \n",
    "        x.columns = x.columns.str.replace(\"shortcode_media.\", \"\")\n",
    "        result = result.append(x)\n",
    "    except:\n",
    "        np.nan\n",
    "        \n",
    "# Just check for the duplicates\n",
    "result = result.drop_duplicates(subset = 'shortcode')\n",
    "result.index = range(len(result.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Can you go to each post (via its URL) and retrieve metadata such as:\n",
    "- Number of likes\n",
    "- Comments (text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download images from pandas data frame\n",
    "\n",
    "Use requests library to download images from the ‘display_url’ in pandas ‘result’ data frame \n",
    "and store them with respective shortcode as file name.\n",
    "\n",
    "(Important Note: Remember that you should respect author’s rights when you \n",
    "download copyrighted content. Do not use images/videos from Instagram for commercial intent).\n",
    "'''\n",
    "import os\n",
    "import requests\n",
    "result.index = range(len(result.index))\n",
    "\n",
    "path_prefix=\"\"\n",
    "directory = \"Instagram_Photos_\" + username\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(path_prefix + directory)\n",
    "\n",
    "for i in range(len(result)):\n",
    "    r = requests.get(result['display_url'][i])\n",
    "    with open(directory + \"/\" + result['shortcode'][i]+\".jpg\", 'wb') as f:\n",
    "                    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go check out the folder Instagram_Photos_davidbeckham/\n",
    "\n",
    "You should see JPG files there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
